{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metode Iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiție și clasificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative sunt tehnici care obțin soluțiile unui sistem liniar prin aproximări succesive la fiecare pas. Acestea sunt de două feluri, staționare și nestaționare. \n",
    "\n",
    "Cele **staționare** sunt metode mai vechi apărute, ușor de înțeles și de implementat. Acestea presupun ca la fiecare pas să se execute aceleași operații pe vectorul curent care reține soluția. În acest laborator vom discuta despre **Jacobi**, **Gauss-Seidel** și **Suprarelaxare** în cadrul metodelor iterative staționare.\n",
    "\n",
    "Metodele __nestaționare__ sunt mai nou apărute, mai greu de implementat, dar mai eficiente. Nu vor fi acoperite în acest laborator, dar ca exemplu am putea menționa **Metoda Gradientului Conjugat**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum funcționează?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative se bazează pe aproximări succesive. Să presupunem că avem de rezolvat sistemul $Ax = b$. Începem rezolvarea cu o aproximare inițială $x = x_0$. La pasul curent ($i$), calculăm o nouă aproximare, bazată pe cea de la pasul anterior ($i - 1$). Astfel, se obține un șir de aproximări $x_0, x_1, x_2, ..., x_k, ...$. Cu cât permitem mai multe iterații, cu atât solutia este mai apropiată de cea exactă. Cu alte cuvinte, cu cât indicele lui x este mai mare, cu atât se apropie mai mult de adevărata soluție a ecuației $Ax = b$. Deci, când $k \\rightarrow \\infty$, șirul de soluții converge la soluția $x = A^{-1}b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forma matriceală a soluției este: <br>\n",
    "$x^{k + 1} = G * x^k + c, k = 0, 1, 2...$ <br>\n",
    "unde $x^{k}$ și $x^{k + 1}$ repezintă aproximările la pașii $k$ si $k + 1$, <br>\n",
    "$G$ este matricea de iterație, iar $c$ este un vector coloană ce vor fi explicate mai jos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum știu că am găsit soluția?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul metodelor iterative nu căutăm soluția exactă, ci căutăm o aprximare cât mai bună a acesteia. Cu cât parcurgem mai multe iterații, cu atât obținem cu aproximare mai bună, însă cum știm că ne putem opri din căutare? \n",
    "\n",
    "Ne oprim când o soluție nu diferă foarte mult de cea precedentă, însemnând că algoritmul converge și valorile nu se vor mai schimba mult din acest moment. Noi stabilim când se întâmplă asta, alegând o toleranță destul de mică, de exemplu 0.001 sau 0.0001. Formula după care ne ghidăm este: \n",
    "$|x^{k + 1} - x^{k}| < tol$\n",
    "\n",
    "#### Observație: \n",
    "Numărul de zerouri dupa virgulă în valoarea lui epsilon oferă precizie. Epsilon = 0.001 oferă o precizie de două zecimale exacte, pe cand 0.0001 oferă trei zecimale exacte.\n",
    "\n",
    "O altă condiție de oprire ar putea fi atingerea numărului maxim de iterații, chiar dacă nu am găsit o aproximare suficient de bună pentru sistemul dat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prea multă teorie, ce se face mai concret? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pornind de la sistemul $Ax = b$, scriem matricea $A$ ca diferență de două matrici, $A = N - P$.\n",
    "Sistemul este prelucrat astfel: <br>\n",
    "$(N - P)x = b$ <br>\n",
    "$Nx - Px = b$ <br>\n",
    "$Nx = Px + b$ | $N^{-1}$ <br>\n",
    "$x = N^{-1}Px + N^{-1}b$ <br>\n",
    "$x = Gx + c$ (doar notații)\n",
    "\n",
    "$G$ este matricea de iterație de care vorbeam mai devreme, care aparține lui $R^{nxn}$, iar $c$ este un vector coloană din $R^n$.\n",
    "\n",
    "#### Condiție de convergență:\n",
    "${\\rho(G)} < 1$, unde ${\\rho(G)} = max|{\\lambda}_{i}|$, numită raza spectrală\n",
    "\n",
    "Pentru **Gauss-Seidel**, putem arăta convergență și dacă demonstrăm că matricea $G$ este diagonal dominantă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matricile $N$ și $P$ sunt calculate, de la o metodă la alta, în funcție de matricea $D$ (diagonala lui $A$), $L$ (matricea formată din elementele de sub diagonala principală a lui $A$) și $U$ (matricea formată din elementele de deasupra diagonalei principale a lui A). \n",
    "\n",
    "#### Exemplu:\n",
    "Fie matricea $A = \n",
    "\\begin{bmatrix}\n",
    "    1 & 5 & -3 \\\\\n",
    "    6 & 10 & 2 \\\\\n",
    "    -1 & 7 & 8 \\\\ \n",
    "    \\end{bmatrix}$ <br>.\n",
    "\n",
    "Atunci, $D =\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 10 & 0 \\\\\n",
    "    0 & 0 & 8 \\\\ \n",
    "    \\end{bmatrix}$\n",
    ", $L =\n",
    "\\begin{bmatrix}\n",
    "    0 & 0 & 0 \\\\\n",
    "    6 & 0 & 0 \\\\\n",
    "    -1 & 7 & 0 \\\\ \n",
    "    \\end{bmatrix}$\n",
    "și $U =\n",
    "\\begin{bmatrix}\n",
    "    0 & 5 & -3 \\\\\n",
    "    0 & 0 & 2 \\\\\n",
    "    0 & 0 & 0 \\\\ \n",
    "    \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [D, L, U] = DivideMatrix(A)\n",
    "    % Completați următoarele linii pentru a calcula D, L, U\n",
    "    % Hint: funcțiile diag, tril, triu\n",
    "    D = NaN;\n",
    "    L = NaN;\n",
    "    U = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[D, L, U] = DivideMatrix([1 5 -3; 6 10 2; -1 7 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[passed, total] = test (\"DivideMatrixTest\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gauss-Seidel** este o metodă iterativă similară cu **Jacobi**, discutată anterior. Diferența între ele este că **Jacobi** calculează soluția de la pasul $i + 1$ bazându-se în totalitate pe soluția de la pasul $i$, pe când **Gauss-Seidel** se bazează pe soluțiia de la pasul $i$, dar și de soluția parțial calculată de la pasul $i + 1$.\n",
    "\n",
    "Mai clar, să zicem ca $x_0 = (a_0, b_0, c_0)$ este soluția inițială și $x_1 = (a_1, b_1, c_1)$ soluția următoare.\n",
    "La pasul 1, Jacobi ar calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$. De asemenea, ar calcula și $b_1$ și $c_1$ tot în funcție de $a_0$, $b_0$ și $c_0$.\n",
    "Gauss-Seidel începe prin a calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$, deoarece nu a calculat încă alte valori la pasul curent. Însă pentru a-l calcula pe $b_1$ folosește, în loc de $a_0$, valoarea lui $a_1$ calculată pentru soluția de la pasul curent. Astfel, $b_1$ e calculat folosind $a_1$, $b_0$ și $c_0$, iar $c_1$ e calculat folosind $a_1$, $b_1$ și $c_0$.\n",
    "\n",
    "#### Observație\n",
    "Gauss-Seidel converge mai repede decât Jacobi, adică găsește o soluție suficient de bună, care să satisfacă relația cu epsilon, în mai puțini pași."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulele de la Gauss-Seidel\n",
    "\n",
    "Pornind de la $Ax = b$ și $A = N - P$, alegem $N = D - L$ și $P = U$. <br> Astfel, $G = N - P = (D - L)^{-1}U$.\n",
    "\n",
    "Soluția recurentă a sistemului este: <br>\n",
    "$$x_i^{p + 1} = \\frac{b_i - \\sum_{j = 1}^{i - 1} a_{ij}x_j^{p + 1} - \\sum_{j = i + 1}^{n} a_{ij}x_j^{p}}{a_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [success] = ConvergesGaussSeidel(A)\n",
    "    % Completați următoarele linii pentru a stabili daca matricea A converge pentru metoda Gauss-Seidel\n",
    "    % Hint: Folosiți funcția DivideMatrix\n",
    "    N = NaN;\n",
    "    P = NaN;\n",
    "    G = NaN;\n",
    "    % Calculați raza spectrală a matricei G\n",
    "    spectral_radius = NaN;\n",
    "    success = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[success] = ConvergesGaussSeidel([1 5 -3; 6 10 2; -1 7 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[passed, total] = test (\"ConvergesGaussSeidel.test\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [x_current_step, step] = GaussSeidel(A, b, x0, tol, max_iter)\n",
    "    % TODO 1: Verificați dacă metoda Gauss-Seidel converge pentru matricea A și în caz contrar returnați [NaN, -1]\n",
    "    success = NaN;\n",
    "    \n",
    "    n = length(b);\n",
    "    x_last_step = x0;\n",
    "    x_current_step = x0;\n",
    "    % Iterează până la numărul maxim de pași acceptat\n",
    "    for step = 1 : max_iter\n",
    "        % Pentru fiecare element din vectorul soluție\n",
    "        for i = 1 : n\n",
    "            % TODO 2: Calculează suma care folosește valori calculate la pasul curent\n",
    "            current_step_sum = NaN;\n",
    "\n",
    "            % TODO 3: Calculează suma care folosește valori calculate la pasul anterior\n",
    "            last_step_sum = NaN;\n",
    "\n",
    "            % TODO 4: Calculează noua valoare a elementului x(i)\n",
    "        endfor\n",
    "\n",
    "        % TODO 5: Verifică daca s-a ajuns la o soluție suficient de bună\n",
    "        % Hint: funcția norm\n",
    "        \n",
    "        % TODO 6: Actualizează soluția precedentă cu cea curentă\n",
    "        x_last_step = x_current_step;\n",
    "    endfor\n",
    "endfunction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
